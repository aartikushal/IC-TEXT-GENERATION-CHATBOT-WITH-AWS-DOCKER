# ğŸ¤– AI Story Generator API (Gemini 2.0 Flash)

A lightweight, high-performance **Text Generation API** built using
**FastAPI** and powered by **Google Gemini 2.0 Flash**. Fully
containerized with **Docker** and optimized for deployment on **AWS
EC2** for scalable cloud-based inference.

## ğŸš€ Features

-   Story Generator API\
-   FastAPI Backend\
-   Gemini 2.0 Flash\
-   Dockerized\
-   AWS EC2 Ready\
-   JSON-based Endpoint

## ğŸ§© Technology Stack

  Layer       Technology         Description
  ----------- ------------------ ----------------------
  Framework   FastAPI            REST API backend
  Model       Gemini 2.0 Flash   Google Generative AI
  Language    Python 3.11        Runtime
  Packaging   Docker             Containerization
  Cloud       AWS EC2            Deployment

## ğŸ§± Project Structure

    â”œâ”€â”€ app.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ supervisord.conf
    â””â”€â”€ README.md

## âš™ï¸ Setup & Local Run

### Add API Key

export OPENAI_API_KEY="YOUR_API_KEY"

### Install Requirements

pip install -r requirements.txt

### Run API

python app.py

## ğŸ³ Docker Deployment

docker build -t gemini-story-api . docker run -d -p 8001:8001
gemini-story-api

## â˜ï¸ AWS EC2 Deployment

Install Docker â†’ Upload files â†’ Build & run container â†’ Open port 8001.

## ğŸŒ Live Endpoint

http://13.51.196.70:8002/docs

## ğŸ“š Example Output

{ "story": "Once upon a time..." }

## ğŸ“„ License

MIT License Â© 2025
